<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Beauty AR Try-On</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      background: #f7f7f7;
    }
    #video {
      position: absolute;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #overlay {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>

  <!-- Load face-api.js -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const context = overlay.getContext('2d');

    // Start camera after models load
    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (err) {
        alert("Camera access denied or not available.");
        console.error(err);
      }
    }

    // Draw lipstick overlay
    function drawLips(landmarks) {
      const lips = landmarks.getMouth();
      context.fillStyle = 'rgba(255, 0, 0, 0.5)';
      context.beginPath();
      lips.forEach((point, index) => {
        if (index === 0) {
          context.moveTo(point.x, point.y);
        } else {
          context.lineTo(point.x, point.y);
        }
      });
      context.closePath();
      context.fill();
    }

    // Run detection loop
    async function onPlay() {
      if (video.readyState === 4) {
        const options = new faceapi.TinyFaceDetectorOptions();
        const result = await faceapi
          .detectSingleFace(video, options)
          .withFaceLandmarks();

        context.clearRect(0, 0, overlay.width, overlay.height);

        if (result) {
          const dims = faceapi.matchDimensions(overlay, video, true);
          const resized = faceapi.resizeResults(result, dims);
          drawLips(resized.landmarks);
        }
      }
      requestAnimationFrame(onPlay);
    }

    // Init: load models, then camera
    async function init() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      await startVideo();
    }

    video.addEventListener('playing', () => {
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;
      onPlay();
    });

    init();
  </script>
</body>
</html>
